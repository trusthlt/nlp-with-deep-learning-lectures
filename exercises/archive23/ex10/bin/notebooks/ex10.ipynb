{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell is copied from the previous exercise\n",
    "import re\n",
    "\n",
    "def load_all_names() -> list[str]:\n",
    "    lines = open('names.txt', 'r').read().splitlines()\n",
    "    \n",
    "    pattern = r'\\[\\[([^\\]]+)\\]'\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for line in lines:\n",
    "        names = re.findall(pattern, line)\n",
    "        if len(names):\n",
    "            result.extend([name.lower() for name in names])\n",
    "    return result\n",
    "\n",
    "all_names = load_all_names()\n",
    "print(all_names[:20])\n",
    "print(len(all_names))\n",
    "\n",
    "# Construct bigram counts tensor\n",
    "# All characters + one special character \".\" for both BOS and EOS\n",
    "\n",
    "chars = sorted(list(set(''.join(all_names))))\n",
    "print(len(chars))\n",
    "print(chars)\n",
    "\n",
    "# add \".\" to zero position\n",
    "chars.insert(0, \".\")\n",
    "print(len(chars))\n",
    "print(chars)\n",
    "\n",
    "# string to index, index to string\n",
    "str_to_idx = {s: i for i, s in enumerate(chars)}\n",
    "idx_to_str = {i: s for s, i in str_to_idx.items()}\n",
    "\n",
    "print(str_to_idx)\n",
    "print(idx_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "import torch\n",
    "\n",
    "block_size = 3  # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "# Task 1: Implement loading data\n",
    "\n",
    "def build_dataset(_block_size: int, list_of_names: list[str]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    result_x: list[list[int]] = []\n",
    "    result_y: list[int] = []\n",
    "    for current_name in list_of_names:\n",
    "        name_with_eos = None\n",
    "\n",
    "        # print(name_with_eos)\n",
    "\n",
    "        context_chars_indices: list[int] = None\n",
    "        for ch in name_with_eos:\n",
    "            pass\n",
    "\n",
    "            # print(''.join(idx_to_str[i] for i in context_chars_indices), '--->', idx_to_str[target_char_index])\n",
    "\n",
    "            # Update the context char list (remove the first char, add the next char)\n",
    "            pass\n",
    "    return torch.tensor(result_x), torch.tensor(result_y)\n",
    "\n",
    "X, Y = build_dataset(block_size, all_names)\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# aaron.\n",
    "# ... ---> a\n",
    "# ..a ---> a\n",
    "# .aa ---> r\n",
    "# aar ---> o\n",
    "# aro ---> n\n",
    "# ron ---> .\n",
    "# tensor([[ 0,  0,  0],\n",
    "#         [ 0,  0,  2],\n",
    "#         [ 0,  2,  2],\n",
    "#         [ 2,  2, 19],\n",
    "#         [ 2, 19, 16],\n",
    "#         [19, 16, 15]])\n",
    "# tensor([ 2,  2, 19, 16, 15,  0])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a05aa98c9b98deb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "176568f1d76573c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_names)\n",
    "n1 = int(0.8 * len(all_names))\n",
    "n2 = int(0.9 * len(all_names))\n",
    "\n",
    "x_train, y_train = build_dataset(block_size, all_names[:n1])\n",
    "x_dev, y_dev = build_dataset(block_size, all_names[n1:n2])\n",
    "x_test, y_test = build_dataset(block_size, all_names[n2:])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "365bb2a8cb390fde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Task 2: Implement MLP with one hidden layer to predict next word\n",
    "# - Shared embeddings for characters\n",
    "# - Concatenate the three embedding vectors\n",
    "# - Train with SGD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c850f8ec085ee3f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Task 3: Use the trained model to generate new names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9908246e33677f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c69ffecd5a1d1ce0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
