{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-gz",
   "metadata": {},
   "source": [
    "# Fine-tuning GPT-2 for Gen-Z Style Rewriting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d15907",
   "metadata": {},
   "source": [
    "- We will try to fine-tune GPT-2 to rewrite formal text into Gen Z style.\n",
    "- For this, we will be using something called **knowledge distillation**.\n",
    "- What is knowledge distillation, you might ask?\n",
    "  - It's when you train / fine-tune a smaller model on a bigger model’s outputs.\n",
    "  - The big model is called the **teacher model**, and the small model is, well, you probably guessed it, the **student model**.\n",
    "- So how exactly will we be doing that?\n",
    "  - We will be generating synthetic data, some call this process **data augmentation**, using the Magistral Small model.\n",
    "    - The script for this is provided: `get_pairs_magistral`. You can take a look, but Magistral Small requires a powerful GPU to run. You might be able to run it with an RTX 4090 (if quantized), but I would assume most of you don’t have this kind of compute power available, so you can simply look at the script, it's very straight to the point.\n",
    "    - The output of Magistral Small is pairs of formal text and Gen Z text.\n",
    "  - We will use the output of Magistral Small throughout the exercise. The file that contains our pairs is `genz_pairs_magistral_diverse_5k.jsonl`.  \n",
    "    (A small note if you’re interested: JSONL is used instead of JSON because JSONL supports streaming the inference output directly, so we don’t have to wait for the whole pipeline to end to get our data.)\n",
    "- HAVE FUN!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from transformers import (\n",
    "    GPT2TokenizerFast,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "# some colors to add some soul\n",
    "RED = \"\\033[91m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "RESET = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## Load JSONL Style-Transfer Dataset\n",
    "\n",
    "Your dataset contains pairs:\n",
    "```\n",
    "{\"original\": \"I am tired\", \"gen_z\": \"lowkey exhausted fr\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jsonl-path",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>gen_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am really tired after studying all night.</td>\n",
       "      <td>Been grinding all night and I’m lowkey exhaust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe how many people are playing th...</td>\n",
       "      <td>It's crazy how many people are playing that ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to finish this report by the end of the...</td>\n",
       "      <td>Gotta wrap up this report by EOD, ya feel me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always check my phone when I wake up in the ...</td>\n",
       "      <td>First thing in the morning, I always gotta che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I always make time for my friends even when I'...</td>\n",
       "      <td>No matter how busy I am, I always make time fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0        I am really tired after studying all night.   \n",
       "1  I can't believe how many people are playing th...   \n",
       "2  I need to finish this report by the end of the...   \n",
       "3  I always check my phone when I wake up in the ...   \n",
       "4  I always make time for my friends even when I'...   \n",
       "\n",
       "                                               gen_z  \n",
       "0  Been grinding all night and I’m lowkey exhaust...  \n",
       "1  It's crazy how many people are playing that ne...  \n",
       "2      Gotta wrap up this report by EOD, ya feel me?  \n",
       "3  First thing in the morning, I always gotta che...  \n",
       "4  No matter how busy I am, I always make time fo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_path = \"genz_pairs_magistral_diverse_5k.jsonl\"\n",
    "\n",
    "df = pd.read_json(jsonl_path, lines=True)\n",
    "print(\"Dataset size:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split",
   "metadata": {},
   "source": [
    "## Train / Validation Split\n",
    "- Tasks: usually we create 3 splits: train, validation, test. But this task is more about creativity, there are methods where we can test our output for stylistic rewriting, but the pairs themselves were generated using another LLM, so I think after we finish fine-tuning our mode, judge it yourself!\n",
    "    - Task 1: 80% train + 20% dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "split-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['original', 'gen_z'],\n",
       "        num_rows: 4001\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['original', 'gen_z'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    # --- Task 1 begins here ---\n",
    "    'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    'validation': Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "    # --- Task 1 ends here ---\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenizer",
   "metadata": {},
   "source": [
    "## Tokenizer & Pair Formatting\n",
    "- Explanation of the next steps:\n",
    "    - GPT-2 is a causal language model. That means it learns by predicting the next token given everything before it.\n",
    "        - So during training, GPT-2 assumes:\n",
    "            - Every token in the input is something it should try to predict.\n",
    "            - But in our task, the input contains two parts:\n",
    "                -  `Original: <formal text> Gen Z:`\n",
    "            - Our target output is this:\n",
    "                - `<gen-z rewrite>`\n",
    "            - We do not want GPT-2 to learn the prompt, only the Gen-Z rewrite.\n",
    "            - That’s why we need to:\n",
    "                - concatenate prompt + output into one sequence\n",
    "                - but mask the prompt labels with -100\n",
    "\n",
    "- Tasks: let's create our tokenization function\n",
    "    - Task 1: format your prompt + target\n",
    "    - Task 2: tokenize?\n",
    "    - Task 3: build your model input (truncation for safety!) + your labels (remember we don't want our model to learn the prompt, this is very essential for style transfer. Hint: -100 for masking)\n",
    "    - Task 4: tokenize your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tokenizer-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e53304b31b847188c3ce06bb719731b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f059f625a3ad46f99111416b9ef23ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 4001\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "prompt_template = \"Original: {src}\\nGen Z: \"\n",
    "MAX_LEN = 1024\n",
    "\n",
    "def tokenize_pair(example):\n",
    "    # --- Task 1 begins here ---\n",
    "    prompt = prompt_template.format(src=example['original'])\n",
    "    target = example['gen_z'] + tokenizer.eos_token\n",
    "    # --- Task 1 ends here ---\n",
    "\n",
    "    # --- Task 2 begins here ---\n",
    "    prompt_ids = tokenizer(prompt, add_special_tokens=False)['input_ids']\n",
    "    target_ids = tokenizer(target, add_special_tokens=False)['input_ids']\n",
    "    # --- Task 2 ends here ---\n",
    "    \n",
    "    # --- Task 3 begins here ---\n",
    "    input_ids = (prompt_ids + target_ids)[:MAX_LEN]\n",
    "    labels = ([-100] * len(prompt_ids) + target_ids)[:MAX_LEN]\n",
    "    # --- Task 3 ends here ---\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "# --- Task 4 begins here ---\n",
    "tokenized_datasets = dataset.map(tokenize_pair)\n",
    "# --- Task 4 ends here ---\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['original','gen_z'])\n",
    "tokenized_datasets.set_format('torch')\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collator-expl",
   "metadata": {},
   "source": [
    "## Data Collator: Dynamic Padding and Masking\n",
    "\n",
    "- We want our batches to look like this at training time:\n",
    "```txt\n",
    "[input_ids]      → padded to max seq len in batch\n",
    "\n",
    "[labels]         → padded, but masked with -100\n",
    "\n",
    "[attention_mask] → tells the model which tokens are padding\n",
    "```\n",
    "- Unlike tokenization (which truncates), batching must:\n",
    "    - Dynamically pad sequences in each batch\n",
    "    - Mask padded label tokens with -100\n",
    "    - Ensure padding does NOT affect loss\n",
    "    - Produce a valid attention_mask\n",
    "- Tasks:\n",
    "    - Task 1: store the tokenizer inside the collator\n",
    "    - Task 2: extract tensors from features (input_ids, labels)\n",
    "    - Task 3: dynamically pad inputs (Pad with pad_token_id)\n",
    "    - Task 4: dynamically pad labels (Pad with -100 — so loss ignores padding)\n",
    "    - Task 5: build attention mask (1 for tokens, 0 for padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collator-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalGenZCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        # --- Task 1 begins here ---\n",
    "        self.tokenizer = tokenizer\n",
    "        # --- Task 1 ends here ---\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # --- Task 2 begins here ---\n",
    "        input_ids  = [torch.tensor(f['input_ids']) for f in features]\n",
    "        labels     = [torch.tensor(f['labels']) for f in features]\n",
    "        # --- Task 2 ends here ---\n",
    "        \n",
    "        # --- Task 3 begins here ---\n",
    "        input_ids = pad_sequence(\n",
    "            input_ids,\n",
    "            batch_first=True,\n",
    "            padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        # --- Task 3 ends here ---\n",
    "\n",
    "        labels = pad_sequence(\n",
    "            labels,\n",
    "            batch_first=True,\n",
    "            padding_value=-100\n",
    "        )\n",
    "        # --- Task 4 begins here ---\n",
    "        \n",
    "        # --- Task 5 begins here ---\n",
    "        attention_mask = input_ids.ne(self.tokenizer.pad_token_id).long()\n",
    "        # --- Task 5 ends here ---\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "data_collator = CausalGenZCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-expl",
   "metadata": {},
   "source": [
    "## Baseline GPT-2 (No Fine-tuning)\n",
    "\n",
    "- Before we fine-tune GPT-2, we want to know:\n",
    "    - How well does the pretrained model already perform on our Gen-Z rewriting task?\n",
    "- We’ll evaluate GPT-2 without training to compute:\n",
    "```txt\n",
    "baseline loss  → cross-entropy on validation set\n",
    "baseline ppl   → perplexity (exp(loss))\n",
    "```\n",
    "- This gives us a reference score so we can measure:\n",
    "    - how much fine-tuning improves the model\n",
    "    - whether our training setup actually helps\n",
    "    - whether we’re overfitting or degrading performance\n",
    "- We did this in previous exercies, before attempting to change things, we need to set a baseline!\n",
    "\n",
    "- Tasks:\n",
    "    - Task 1: load the `gpt2`\n",
    "    - Task 2: define evaluation-only training arguments (let's go with `batch_size = 4`)\n",
    "    - Task 3: create a Trainer for evaluation\n",
    "    - Task 4: run evaluation on the validation split\n",
    "    - Task 5: calculate the perplexity from loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baseline-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline perplexity: 21.86\n"
     ]
    }
   ],
   "source": [
    "# --- Task 1 begins here ---\n",
    "baseline_model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "# --- Task 1 ends here ---\n",
    "\n",
    "baseline_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# --- Task 2 begins here ---\n",
    "baseline_args = TrainingArguments(\n",
    "    output_dir='./gpt2_genz_baseline',\n",
    "    per_device_eval_batch_size=4,\n",
    "    report_to='none'\n",
    ")\n",
    "# --- Task 2 ends here ---\n",
    "\n",
    "# --- Task 3 begins here ---\n",
    "baseline_trainer = Trainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args,\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "# --- Task 3 ends here ---\n",
    "\n",
    "# --- Task 4 begins here ---\n",
    "baseline_eval = baseline_trainer.evaluate()\n",
    "# --- Task 4 ends here ---\n",
    "\n",
    "# --- Task 5 begins here ---\n",
    "baseline_loss = baseline_eval['eval_loss']\n",
    "baseline_ppl = math.exp(baseline_loss)\n",
    "# --- Task 5 ends here ---\n",
    "\n",
    "print(f\"Baseline perplexity: {baseline_ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-expl",
   "metadata": {},
   "source": [
    "## Fine-tune GPT-2 on Gen-Z pairs\n",
    "- A quick recap of our training objective:\n",
    "```txt\n",
    "Input  → \"Original: <text>\"\n",
    "Output → \"Gen Z: <rewritten text>\"\n",
    "```\n",
    "- Tasks:\n",
    "    - Task 1: define our training arguments (`batch_size = 4`)\n",
    "    - Task 2: initialize the Trainer\n",
    "    - Task 3: let's fine-tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "train-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1001' max='1001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1001/1001 02:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.518200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.193700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.977800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.748800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.596500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.753800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.698100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.589400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.676700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.484600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.541900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.536100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.433200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.492100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.401800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.335100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.434500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.435600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.315700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.420200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.362200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.317400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.336600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.337800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.379200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1001, training_loss=1.5254824745071518, metrics={'train_runtime': 155.7497, 'train_samples_per_second': 25.689, 'train_steps_per_second': 6.427, 'total_flos': 257429298816000.0, 'train_loss': 1.5254824745071518, 'epoch': 1.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# --- Task 1 begins here ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./finetuned_gpt2_genz',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=20,\n",
    "    report_to='none'\n",
    ")\n",
    "# --- Task 1 ends here ---\n",
    "\n",
    "# --- Task 2 begins here --- \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "# --- Task 2 ends here ---\n",
    "\n",
    "# --- Task 3 begins here ---\n",
    "trainer.train()\n",
    "# --- Task 3 ends here ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-expl",
   "metadata": {},
   "source": [
    "## Evaluation After Fine-tuning\n",
    "- Now that we fine-tuned our model, let's compare the perplexity before and after fine-tuning\n",
    "- Tasks:\n",
    "    - Task 1: get the evaluation results\n",
    "    - Task 2: compute the perplexity after fine-tuning\n",
    "    - Task 3: plot a simple bar chart to visualize the difference (use `pyplot`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eval-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity after fine-tuning: 3.38\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Task 1 begins here ---\n",
    "eval_results = trainer.evaluate()\n",
    "# --- Task 1 ends here ---\n",
    "\n",
    "# --- Task 2 begins here ---\n",
    "eval_loss = eval_results['eval_loss']\n",
    "eval_ppl = math.exp(eval_loss)\n",
    "# --- Task 2 ends here ---\n",
    "\n",
    "print(f\"Perplexity after fine-tuning: {eval_ppl:.2f}\")\n",
    "\n",
    "metrics = [\"Baseline\", \"Fine-tuned\"]\n",
    "values = [baseline_ppl, eval_ppl]\n",
    "\n",
    "# --- Task 3 begins here ---\n",
    "plt.figure()\n",
    "plt.bar(metrics, values)\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.title(\"Baseline vs Fine-tuned Perplexity\")\n",
    "plt.show()\n",
    "# --- Task 3 ends here ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gen-demo",
   "metadata": {},
   "source": [
    "## Try Gen-Z Rewrite Generation\n",
    "- Now let's see how's our small fine-tuned model doing\n",
    "- You have written functions to run inference before, so this time I'll give it to you on a silver platter :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "gen-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91mOriginal \u001b[0m\n",
      "================================================================================\n",
      "I've been trying to balance my work, studies, and social life lately, but it\n",
      "feels like everything keeps happening at once. I’m grateful for the\n",
      "opportunities I have, yet I can’t deny that the constant pressure is\n",
      "starting to wear me down. Sometimes I just want a quiet evening to\n",
      "disconnect from notifications, clear my thoughts, and remind myself that I\n",
      "don’t have to keep up with everyone all the time.\n",
      "\u001b[1m\u001b[94mGen-Z \u001b[0m\n",
      "================================================================================\n",
      "I’ve been keeping my work and studies in check since I left school. It’s\n",
      "tough to stop it when life’s always a little bit too much. It’s kinda\n",
      "stressing me out right now, but I’m glad I got what I needed, but the\n",
      "pressure is just so much and it’s making me uncomfortable. Sometimes I just\n",
      "wanna check my phone for notifications, clear my head, and just take time\n",
      "out to relax.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def rewrite_gen_z(text):\n",
    "    prompt = prompt_template.format(src=text)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_length=400,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"Gen Z:\")[-1].strip()\n",
    "\n",
    "sample = \"I've been trying to balance my work, studies, and social life lately, but it feels like everything keeps happening at once. I’m grateful for the opportunities I have, yet I can’t deny that the constant pressure is starting to wear me down. Sometimes I just want a quiet evening to disconnect from notifications, clear my thoughts, and remind myself that I don’t have to keep up with everyone all the time.\"\n",
    "original = textwrap.fill(sample, width=76)\n",
    "gen_z = textwrap.fill(rewrite_gen_z(sample), width=76)\n",
    "\n",
    "print(f\"{BOLD}{RED}Original {RESET}\")\n",
    "print(\"=\" * 80)\n",
    "print(original)\n",
    "print(f\"{BOLD}{BLUE}Gen-Z {RESET}\")\n",
    "print(\"=\" * 80)\n",
    "print(gen_z)\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teach (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
