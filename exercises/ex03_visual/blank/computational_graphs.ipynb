{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graphs Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166bf2fb",
   "metadata": {},
   "source": [
    "## Nodes implementations (from last year exercise)\n",
    "- Note: If you want a good challenge, try to implement this yourself. \n",
    "    - Link: [Old Exercise 3](https://github.com/trusthlt/nlp-with-deep-learning-lectures/tree/main/exercises/archive24/ex03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02749fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalarNodeCache:\n",
    "    def __init__(self):\n",
    "        self.value: Optional[float] = None\n",
    "        self.local_partial_derivatives_wrt_arguments: Optional[List[float]] = None\n",
    "        self.global_derivative_wrt_self: Optional[float] = None\n",
    "\n",
    "class ScalarNode:\n",
    "\n",
    "    def __init__(self, arguments: List['ScalarNode']) -> None:\n",
    "        self._parents: List['ScalarNode'] = []\n",
    "        self._arguments = arguments\n",
    "        for arg in self._arguments:\n",
    "            arg._parents.append(self)\n",
    "        self._cache = ScalarNodeCache()\n",
    "\n",
    "    def value(self) -> float:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def local_partial_derivatives_wrt_arguments(self) -> List[float]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def find_self_position_in_parents_arguments(self, parent: 'ScalarNode') -> int:\n",
    "        for i, arg in enumerate(parent._arguments):\n",
    "            if self == arg:\n",
    "                return i\n",
    "        raise Exception(\"Self found not in parent's arguments\")\n",
    "\n",
    "    def global_derivative_wrt_self(self) -> float:\n",
    "        # caching for efficiency\n",
    "        if self._cache.global_derivative_wrt_self is not None:\n",
    "            return self._cache.global_derivative_wrt_self\n",
    "\n",
    "        if len(self._parents) == 0:\n",
    "            # output node: derivative of output wrt itself is 1.0\n",
    "            return 1.0\n",
    "        else:\n",
    "            result = 0.0\n",
    "            # generalized chain rule: sum over parents of (d parent / d self) * (global d output / d parent)\n",
    "            for p in self._parents:\n",
    "                idx = self.find_self_position_in_parents_arguments(p)\n",
    "                parent_to_self = p.local_partial_derivatives_wrt_arguments()[idx]\n",
    "                parent_global = p.global_derivative_wrt_self()\n",
    "                result += parent_to_self * parent_global\n",
    "\n",
    "            self._cache.global_derivative_wrt_self = result\n",
    "            return result\n",
    "\n",
    "    def clear_cache_downwards(self):\n",
    "        # Clear caches for this node and all descendant argument nodes.\n",
    "        visited = set()\n",
    "        stack = [self]\n",
    "        while stack:\n",
    "            n = stack.pop()\n",
    "            if id(n) in visited:\n",
    "                continue\n",
    "            visited.add(id(n))\n",
    "            # reset cache fields\n",
    "            if hasattr(n, '_cache') and n._cache is not None:\n",
    "                n._cache.value = None\n",
    "                n._cache.local_partial_derivatives_wrt_arguments = None\n",
    "                n._cache.global_derivative_wrt_self = None\n",
    "            for a in getattr(n, '_arguments', []):\n",
    "                stack.append(a)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<{self.__class__.__name__} at {hex(id(self))}>'\n",
    "\n",
    "class ConstantNode(ScalarNode):\n",
    "\n",
    "    def __init__(self, value: float) -> None:\n",
    "        super().__init__([])\n",
    "        self._value = value\n",
    "\n",
    "    def value(self) -> float:\n",
    "        return self._value\n",
    "\n",
    "    def local_partial_derivatives_wrt_arguments(self) -> List[float]:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "class SumNode(ScalarNode):\n",
    "\n",
    "    def value(self) -> float:\n",
    "        if self._cache.value is not None:\n",
    "            return self._cache.value\n",
    "        result = 0.0\n",
    "        for arg in self._arguments:\n",
    "            result += arg.value()\n",
    "        self._cache.value = result\n",
    "        return result\n",
    "\n",
    "    def local_partial_derivatives_wrt_arguments(self) -> List[float]:\n",
    "        # derivative wrt each argument is 1.0\n",
    "        return [1.0] * len(self._arguments)\n",
    "\n",
    "class ProductNode(ScalarNode):\n",
    "\n",
    "    def value(self) -> float:\n",
    "        if self._cache.value is not None:\n",
    "            return self._cache.value\n",
    "        result = 1.0\n",
    "        for arg in self._arguments:\n",
    "            result *= arg.value()\n",
    "        self._cache.value = result\n",
    "        return result\n",
    "\n",
    "    def local_partial_derivatives_wrt_arguments(self) -> List[float]:\n",
    "        if self._cache.local_partial_derivatives_wrt_arguments is not None:\n",
    "            return self._cache.local_partial_derivatives_wrt_arguments\n",
    "        result = [0.0] * len(self._arguments)\n",
    "        for i in range(len(self._arguments)):\n",
    "            ith = 1.0\n",
    "            for j in range(len(self._arguments)):\n",
    "                if i != j:\n",
    "                    ith *= self._arguments[j].value()\n",
    "            result[i] = ith\n",
    "        self._cache.local_partial_derivatives_wrt_arguments = result\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0325b30b",
   "metadata": {},
   "source": [
    "# A function we will be using to visualize things!\n",
    "- Here's a quick summary of how to use the draw_graph function:\n",
    "    - Basic Usage:\n",
    "        ```py\n",
    "        draw_graph(root, use_full_labels=True, figsize=(6,4))\n",
    "        ```\n",
    "    - Parameters:\n",
    "        - `root`: The root node of your computational graph\n",
    "        - `use_full_labels`:\n",
    "            - `True`: Shows full expressions with values (e.g., \"s = a+b (5.5)\")\n",
    "            - `False`: Shows simplified labels with values (e.g., \"s (5.5)\")\n",
    "        - `figsize`: Tuple for plot size (width, height) in inches\n",
    "    - Node Colors:\n",
    "        - Orange: Root node\n",
    "        - Light Blue: Constant nodes\n",
    "        - Light Green: Operation nodes (Sum, Product)\n",
    "- You can refactor it, to change colors, the info displayed for each node etc...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a29523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(root, use_full_labels=True, figsize=(6,4)):\n",
    "    G = nx.DiGraph()\n",
    "    visited = set()\n",
    "    stack = [root]\n",
    "    node_info = {}  \n",
    "    node_dict = {} \n",
    "    \n",
    "    while stack:\n",
    "        n = stack.pop()\n",
    "        if id(n) in visited:\n",
    "            continue\n",
    "        visited.add(id(n))\n",
    "        \n",
    "        node_dict[id(n)] = n\n",
    "        \n",
    "        if hasattr(n, '_name'):\n",
    "            if use_full_labels:\n",
    "                if isinstance(n, ConstantNode):\n",
    "                    label = f\"{n._name} ({n._value:.1f})\"\n",
    "                elif isinstance(n, SumNode):\n",
    "                    args = [f\"{a._name if hasattr(a, '_name') else '?'}\" for a in n._arguments]\n",
    "                    label = f\"{n._name} = \" + '+'.join(args)\n",
    "                    try:\n",
    "                        val = n.value()\n",
    "                        label += f\" ({val:.1f})\"\n",
    "                    except:\n",
    "                        pass\n",
    "                elif isinstance(n, ProductNode):\n",
    "                    args = [f\"{a._name if hasattr(a, '_name') else '?'}\" for a in n._arguments]\n",
    "                    label = f\"{n._name} = \" + '*'.join(args)\n",
    "                    try:\n",
    "                        val = n.value()\n",
    "                        label += f\" ({val:.1f})\"\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                if isinstance(n, ConstantNode):\n",
    "                    label = f\"{n._name} ({n._value:.1f})\"\n",
    "                else:\n",
    "                    try:\n",
    "                        val = n.value()\n",
    "                        label = f\"{n._name} ({val:.1f})\"\n",
    "                    except:\n",
    "                        label = n._name\n",
    "        else:\n",
    "            label = f\"Node_{id(n)}\"\n",
    "        \n",
    "        node_info[id(n)] = label\n",
    "        G.add_node(id(n))\n",
    "        for a in getattr(n, '_arguments', []):\n",
    "            G.add_edge(id(a), id(n))\n",
    "            stack.append(a)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    node_colors = []\n",
    "    for node in G.nodes():\n",
    "        if node == id(root):\n",
    "            node_colors.append('orange')\n",
    "        elif isinstance(node_dict[node], ConstantNode):\n",
    "            node_colors.append('lightblue')\n",
    "        else:\n",
    "            node_colors.append('lightgreen')\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=False, \n",
    "            node_color=node_colors,\n",
    "            node_size=1000, arrows=True)\n",
    "    \n",
    "    pos_attrs = {}\n",
    "    for node, coords in pos.items():\n",
    "        pos_attrs[node] = (coords[0], coords[1] + 0.085)\n",
    "    nx.draw_networkx_labels(G, pos_attrs, node_info, font_size=12)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42066501",
   "metadata": {},
   "source": [
    "### Exercise 1: Simple function\n",
    "1. Create two constant nodes $a$ and $b$, then create a sum node $s=a+b$\n",
    "2. In the Markdown Cell below, calculate the partial derivatives of $s$ wrt to $a$ and $b$. Calculate the global derivatives too.\n",
    "3. Print the partial derivatives of $s$ wrt to $a$ and $b$\n",
    "4. Using the `draw_graph` function above, try to visualize the computational graph of $s=a+b$\n",
    "\n",
    "Note: Use the values $a=2.0$ and $b=3.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3e0ae",
   "metadata": {},
   "source": [
    "### Your Solution for 2. goes here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61b70aa",
   "metadata": {},
   "source": [
    "**2.: Solve me**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94576433",
   "metadata": {},
   "source": [
    "### Your solutions for 1., 3. and 4. should go below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e99b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"just a placeholder\"\n",
    "# visualize (provided only for this exercise)\n",
    "draw_graph(s)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c59ea",
   "metadata": {},
   "source": [
    "### Exercise 2: Still a simple function\n",
    "1. Create 3 constant nodes $a$, $b$ and $c$, then create a product node $p=a\\cdot b\\cdot c$\n",
    "2. In the Markdown Cell below, calculate the partial derivatives of $p$ wrt to $a$, $b$ and $c$. Calculate the global derivatives too.\n",
    "3. Print the partial derivatives of $s$ wrt to $a$ and $b$\n",
    "4. Using the `draw_graph` function above, try to visualize the computational graph of $p=a\\cdot b\\cdot c$\n",
    "\n",
    "Note: $a=2.0$, $b=4.0$ and $c=5.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf561e0",
   "metadata": {},
   "source": [
    "**Your solution for 2.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45039f64",
   "metadata": {},
   "source": [
    "**Your Solution for 1.,3. and 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a7d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b69fcd",
   "metadata": {},
   "source": [
    "### Exercise 3: Not so simple function\n",
    "\n",
    "From what you learnt earlier, try to create a computational graph for this function: $m = (a+b)\\cdot(a+c)\\cdot b$:\n",
    "1. From what you learnt earlier, try to create a computational graph for this function: $m = (a+b)\\cdot(a+c)\\cdot b$:\n",
    "2. In the Markdown Cell below, calculate the partial derivatives of $m$ wrt to $a$, $b$ and $c$. Calculate the global derivatives too.\n",
    "4. Using the `draw_graph` function above, try to visualize the computational graph of $m = (a+b)\\cdot(a+c)\\cdot b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e271e",
   "metadata": {},
   "source": [
    "**Your Solution to 2.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a2661",
   "metadata": {},
   "source": [
    "**Your solutions to 1. and 3. should go below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a17bccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8cb1013",
   "metadata": {},
   "source": [
    "### Exercise 4: Finally, an actual function!\n",
    "- We want to implement $(a - x)^2 + b\\cdot(y - x^2)^2$ (Rosenbrock Function) using constants, products and sums.\n",
    "- Use these values: $a=1.0$, $b=1.5$, $x=-1.0$ and $y=0.5$\n",
    "1. Like you did in previous exercises: Calculate the partial derivatives wrt $a$,$b$,$x$ and $y$, also the global derivatives.\n",
    "2. Visualize the Rosenbrock Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d27cce",
   "metadata": {},
   "source": [
    "**Your solution to 1. should go below**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c283b8a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373b3ee",
   "metadata": {},
   "source": [
    "**Your solution to 2.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59740371",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teach (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
